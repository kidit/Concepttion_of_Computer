8장

1. Deadlock (교착 상태)

발생 필요 조건

    1. Mutual exclusion (상호배제) 

        1. 자원을 한 번에 한 스레드에게만 할당 (배타적 점유)

        2.  자원을 사용할 수 없는 경우 자원이 해제될 때까지 요청 스레드를 지원함

    2. Hold and wait (점유 & 대기)

        1. 한 이상의 자원을 점유한 스레드가 다른 스레드가 점유한 자원을 추가로 얻기 위해 대기

    3. No preemption (비선점 : 강제 자원 반환 불가)

        1. 스레드에게 할당된 자원을 강제로 빼앗지 못함.

        2. 자원을 보유한 프로세스만 작업이 완료되면 자발적으로 해당 자원을 해제할 수 있음

    4. Circular wait (순환 대기)

        1. 한 그룹의 스레드들에서 각 스레드가 다른 스레드가 소유한 자원을 요청하는 고려 형성

        2. 각 프로세스는 다음 프로세스가 점유하고 있는 자원을 대기 중

조건이 모두 발생할 시 -> 시스템은 교착 상태에 빠짐

2. Respirce Allocation Graph (자원 할당 그래프)

    1. 정점, 간선

        1. 프로세스 P (언으로 표시)

        2. 자원 R (사각형 표시)

        3. Request edge (요청 간선) - directed edge P_i -> R_j

        4. Assignment edge (할당 간선) = directed edge R_j -> P_i

    2. If graph contains no cycles -> no Deadlock

9장

1. Protection

    1. 프로세스가 해당 주소 공간에 있는 주소에만 접근하도록 지원 - Legal address

    2. Provide -> a pair of base & limit register -> define the logical address space

        1. Base : the smallest legal physical memory address

        2. Limit : the size of the range
    
2. Hardware Address Protection

    1. CPU는 다음과 같이 확인

        1. Base <= CPU && Base + limit > CPU

    2. The instructions to loading the base and limit registers are privileged

        1. Kernel mode, OS only -> 사용자 프로그램은 변경 못함

3. Logical Vs Physical Address space

    1. Physical address space -> binding logical address space = 메모리 관리 핵심

        1. Logical address -> generated by the CPU : also referred to as virtual address

        2. Physical address -> address seen by the memory unit

    2. Logical and physical addresses are the same
    
        1. compile - time
        2. load - time address - binding schemes

    3. Logical (virtual) and physical addresses differ

        1. execution - time address - binding schemes

    4. Logica address space : 프로그램에 의해 생성된 모든 논리 주소의 집합

    5. Physical address space : 프로그램에 의해 생성된 모든 물리적 주소 집합

4. binding of instructions and Data to memory

    1. Three different stages

        1. Compile time

        2. Load time

        3. Execution time

5. memory - Management unit (MMU)

    1. Hardware device that at run time maps virtual to physical address

        CPU -> (logical address) -> MMU -> (physical address) -> physical memory

6. Variable Partition (가변 파티션)

    1. Multiple - partition allocation

        1. Degree of multiprogramming limited by number of partitions

        2. Variable - partition size for effeciency

            1. Sized to a given process needs
        
        3. Hole - block of available memory

            1. holes of various size are scattered throughout memory
        
        4. When a process arrives -> allocated memory from a hole large enough to accommodate instructions

        5. Process exiting frees its partition, adjacent free partitions combined
    
    2. Operating System maintains information about

        1. allocated partitions

        2. free partitions (hole)

7. Dynamic Storage - Allocation Problem

    1.  How to satisfy a request of size n from a list of free holes?
    
        1. First -fit : first hole that is big enough

        2. Best - fit : smallest hole that is big enough

            1. must search entire list

            2. unless ordered by size

                1. Produces the smallest leftover hole
            
        3. Worst - fit : Allocate the largest hole

            1. must also search entire list

                1. Produces the largest leftover holes

8. Fragmentation

    1. External Fragmentation (외부 단편화) - 총 메모리 공간이 요청을 충족시키기 위해 존재

        1. 불연속적임
    
    2. Internal Fragmentation (내부 단편화) - 할당된 메모리는 요청된 메모리보다 약간 클 수 있음

        1. 크기 차이는 파티션 내부에 메모리지만 사용 안 됨

    3. First fit analysis reveals that given N block allocated

        1. another o.5 N blocks lost to Fragmentation

        2. 1/3 may be unusable -> 50 - percent rule

9. Paging

    1. Physical address space of a process can be noncontiguous

        1. process is allocated physical memory whenever the latter is available

            1. Avoids external Fragmentation and compaction
        
        2. Divide physical memory into fixed - size blocks called frames

            1. Size is power of 2

            2. between 512 bytes and 16M bytes

        3. Divide logical memory into blocks of same size called pages

        4. Keep track of all free frames

        5. To run a program of size N pages

            1. need to find N free frames and load program
        
        6. Set up a page table to translate logical to physical addresses

        7. Backing store likewise split into pages

        8. Still have Internal Fragmentation

10. memory Protection

    1. Memory protection 구현

        1. 읽기 전용 또는 읽기 / 쓰기 액세스가 허용되는지 여부를 나타내기 위해 보호 비트를 각 ㅍ프레임과 연결

        2. Can also add more bits to indicate page execute - only , and so on

    2. Valid - invalid bit attached to each entry in the page table

        1. "valid" 연결된 페이지 -> 프로세스의 논리적 주소 공간에 있음 = 합법적인 페이지임을 나타냄

        2. "Invalid" 페이지 -> 프로세스의 논리적 주소 공간에 없음을 나타냄

        3. Or use page - table length register (PTLR)

    3. Any violations result in a trap to the Kernel

11. Inverted Page table

    1. Decreases memory needed to store each page table

    2. But increases time needed to search the table

        1. when a page reference occurs
    
    3. Use hash table to limit the search to one - or at most a frw -page - table

        1. TLB can accelerate access

    4. But how to implement shared memory?

        1. Cannot be used with inverted page table

        2. One mapping of a virtual address to the shared physical address

10장

1.Demand Paging

    1. 필요할 때만 페이지를 메모리로 가져옴

        1. Less I/O needed, no unnecessarty I/O

        2. Less memory needed

        3. Faster response & more users

    2. Similar to paging system with swapping

        1. diagram on right
    
    3. Page is needed -> reference to it

        1. Invalid reference -> abort (중단)

        2. Not - in - memory -> bring to memory

2. Valid - invalid Bit

    1. With each page table entry, a valid - invalid bit is associated

        1. v -> in - memory - memory resident

        2. i -> not - in - memory
    
    2. initially valid - invalid bit is set to i on all entries

    3. During MMU address translation

        1. if valid - invalid bit in page table entry : page fault

3. Free - Frame List

    1. Page fault가 발생 -> OS : secondary storage 0-> page -> main memory

    2. Most operating systems maintain a free-frame list

        1. a pool of free frames for satisfying such requests.
    
    3. Operating system typically allocate free frames using a technique known

        1. Zero - fill - on - demand : the content of the frames zeroed-out (erased)

        2. before being allocated
    
    4. When a system starts up, all available memory is placed on the free-frame list


4. Copy - on - Write

    1. Copy - on - Write (COW) allows both parent and child processes to initially share the same pages in memory

        1. Only then is the page copied if either process modifies a shared page.

    2. COW allows more efficient process creation as only modified pages are copied

    3. In general, free pages are allocated from a pool of zero-fill-on-demand pages

        1. Pool should always have free frames for fast demand page execution

            1. Don't want to have to perform further processing on a page fault, such as freeing a frame

    4. vfork() variation on fork() system call has parent suspend and child using that.

        1. copy - on - write address space of parent

            1. Designed to have child call exec()

            2. Very efficient

5. First - In - First - Out (FIFO) Algorithm

    1. Reference string: 1,2,3,4,1,2,5,1,2,3,4,5

    2. 3 frames (3 pages can be in memory at a time per process)

        [1, NULL, NULL]
        [1, 2, NULL]
        [1, 2, 3]
        [4, 2, 3] -> 맨 앞자리 수 바뀜
        [4, 1, 3] -> 두 번째 자리 수 바뀜
        [4, 1, 2] -> 세 번째 자리 수 바뀜
        [5, 1, 2] -> 다시 맨 앞자리 수 바뀜
         X [5, 1, 2] -> 배열 안에 같은 수가 있어서 패스됨
         X [5, 1, 2] -> 배열 안에 같은 수가 있어서 패스됨
        [5, 3, 2]
        [5, 3, 4]

6. Optimal Algorithm

    1. Replace page that will not be used for longest period

        1. 9 is optimal for the example

    2. How do you know this?

        1. Can't read the future
    
    3. 알고리즘이 얼마나 잘 수행되는지 측정

    4. Reference string: 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1

    5. 3 frames (same)

        [7, NULL, NULL]
        [7, 0, NULL]
        [7,0,1]
        [2,0,1]
        X [2,0,1] -> 같은 수가 있어서 생략 (0)
        [2,0,3]
        X [2,0,3] -> 같은 수가 있어서 생략 (0)
        [2,4,3]
        X [2,4,3] -> 같은 수가 있어서 생략 (4)
        X [2,4,3] -> 같은 수가 있어서 생략 (2)
        X [2,4,3] -> 같은 수가 있어서 생략 (3)
        [2,0,3]
        X [2,0,3] -> 같은 수가 있어서 생략 (0)
        X [2,0,3] -> 같은 수가 있어서 생략 (3)
        x [2,0,3] -> 같은 수가 있어서 생략 (2)
        [2,0,1]
        x [2,0,1] -> 같은 수가 있어서 생략 (2)
        x [2,0,1] -> 같은 수가 있어서 생략 (0)
        x [2,0,1] -> 같은 수가 있어서 생략 (1)
        [7,0,1]
        x [7,0,1] -> 같은 수가 있어서 생략 (0)
        x [7,0,1] -> 같은 수가 있어서 생략 (1)

7. Least Recently Used (LRU) Algorithm

    1. Use past knowledge rather than future

    2. Replace page that has not been used in the most amount of time

    3. Associate time of last use with each page

    4. Reference string: 7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1

    5. 3 frames (same)

        [7, NULL, NULL]
        [7, 0, NULL]
        [7,0,1]
        [2,0,1]
        x [2,0,1] -> 같은 수가 있어서 생략 (0)
        [2,0,3]
        x [2,0,3] -> 같은 수가 있어서 생략 (0)
        [4,0,3]
        [4,0,2]
        [4,3,2]
        [0,3,2]
        x [0,3,2] -> 같은 수가 있어서 생략 (3)
        x [0,3,2] -> 같은 수가 있어서 생략 (2)
        [1,3,2]
        x [1,3,2] -> 같은 수가 있어서 생략 (2)
        [1,0,2]
        x [1,0,2] -> 같은 수가 있어서 생략 (1)
        [1,0,7]
        x [1,0,7] -> 같은 수가 있어서 생략 (0)
        x [1,0,7] -> 같은 수가 있어서 생략 (1)

    6. 12 faults - better than FIFO, but worse than Opt

    7. Generally good algorithm and frequently used

    8. But how to implement

8. Enhanced Second - Chance Algorithm

    1. Improve algorithm by using reference bit and modify bit in concert
        
        1. if available
    
    2. Take ordered pair (refernece, modify):

        1. 낮은 등급 : (0,0)
            
            1. 최근에 사용하지 않음

            2. 수정하지 않음

            3. 교체하기 가장 좋은 페이지
        
        2. (0,1)

            1. not recently used but modified

            2. not quite as good

            3. must write out before Replacement

        3. (1,0) 
            
            1. recently used but clean

            2. probably will be used again soon
        
        4. 높은 등급 : (1,1)

            1. recently used and modified

            2. probably will be used again soon

            3. need to write out before Replacement
    
    3. When page replacement called for, use the clock scheme (second chance)

        1. But use the four classes to replace page in lowest non-empty class

            1. Might need to search circular queue several times

9. Fixed Allocation
    
    1. Equal allocation (균등 할당)

        1. For example -> if there are 100 frames and 5 processes, give each process 20 frames

            1. (after allocating frames for the OS)

            2. Keep some as free frame buffer pool
        
    2. Proportional allocation (비례 할당)

        1. Allocate according to the size of process

            1. Dynamic as degree of multiprogramming, process sizes change

                S_i = size of process p_i

                S = (sum) S_i

                m = total number of frames

                a_i = allocation for p_i = s_i / s * main

10. Global Vs Local Allocation

    1. Global replacement

        1. process selects a replacement frame from the set of all frames

            1. one process can take a frame from another

                1. But then process execution time can vary greatly

                2. But greater throughput (처리량) so more common
        
        2. Local replacement

            1. each process selects from only its own set of allocated frames
                
                1. More consistent per - process performance

                2. But possibly underutilized memory

11장

1. Hard disk drives

    1. Positioning time

        1. move disk arm to desired cylinder (seek time)

        2. equals random - access time

    2. Time for desired sector to rotate under the disk head

        1. rotational latency
    
2. NAND Flash Controller Algorithms

    1. with no overwrite, pages end up with mix of valid and invalid data

    2. To track which logical blocks are valid

        1. controller maintains flash translation layer (FTL) table

    3. Also implements garbage collection to free invalid page space

    4. Allocates overprovisioning to provide working space for GC

        1. 전체 중 20%정도를 따로 분리하여 항상 쓸 수 있는 pages 확보

    5. Each cell has lifespan, so wear leveling needed to write equally to all cells


3. HDD Scheduling

    1. the operating system is responsible for using hardware efficiently for the disk drives

        1. it means that having a fast access time and dsk bandwidth

    2. Minimize seek time

    3. Seek time ~= seek distance

    4. Disk bandwidth is the total number of bytes transferred

        1. divided by the total time between the first request for service

        2. and the completion of the last transfer

4. NVM Scheduling

    1. No disk heads or rotational latency but still rom for optimization

    2. In RHEL 7 NOOP (no scheduling) is used but adjacent LBA requests are combined

        1. NVM best at random I/O, HDD at sequential

        2. throughput can be Similar

        3. Input / output operations per second (IOPS) much higher with NVM

            1. hundreds of thousands VS hundreds
        
        4. But write amplification can decrease the performance advantage

            1. one write, causing garbage collection and many read / writes

12장

1. I/O Hardware

    1. Incredible variety of I/O devices

        1. Storage

        2. Transmission

        3. Human - interface

        4. Controller

            1. electronics that operate and control port, bus, devices

                1. 입출력 장치와 CPU 사이의 통신을 중개하는 장치
        
        5. Devices have addresses, used by

            1. Direct I/O instructions

            2. Memory-mapped I/O

                1. Device data and command registers mapped to processor address space

                2. Especially for large address spaces (graphics)

                3. Both memory and I/O devices use the same address space

2. Interrupts

    1. Interrupts handler receives Interrupts
        
        1. Maskable to ignore or delay some interrupts

            1. it can be turned off

    2. Interrupts vector to dispatch interrupt to correct handler

        1. Context switch at start and end

        2. based on priority

        3. Some nonmaskable - reserved for events such as unrecoverable memory errors

        4. Interrupt chaining if ore than one device at same interrupt number

3. Direct Memory Access

    1. Used to avoid programmed I/O (one byte at a time) for large data movement

    2. Requires DMA Controller

    3. Bypasses CPU to transfer data directly between I/O device and Memory

4. Nonblocking and Asynchronous I/O

    1. Blocking - process suspended until I/O completed

        1. Easy to use and understand

        2. Insufficient for same needs

    2. Nonblocking - I/O call returns as much as available

        1. User interface, data copy (buffered I/O)

        2. Implemented via multi-threading

        3. Returns quickly with count of bytes read or written

        4. select() to find if data ready then read() or write() to transfer

    3. Asynchronous - process runs while I/O executes

        1. Difficult to use

        2. I/O subsystem signals process when I/O completed

5. Kernel I/O subsystem

    1. Kernel I/O subsystem

        1. Kernels provide many services related to I/O

    2. Scheduling

        1. Some I/O request ordering via per-device queue

        2. Some OSs try fairness, priority

        3. Some implement Quality Of service

    3. Buffering - store data in memory while transferring between devices

        1. To cope with device speed mismatch

        2. To cope with device transfer size mismatch
        
        3. To maintain "copy semantics"
            
            1. 시스템 콜 시점의 데이터 유지 보장

        4. Double buffering - two copies of the data

            1. use two buffers to relax timing requirements

                1. kernel and User

                2. varying sizes

                3. Full / being processed and not - full / being used

                4. Copy-on-write can be used for efficiency in some cases
        
        5. Caching - faster device holding copy of data

            1. Always just a copy

            2. Key to performance

            3. Sometimes combined with buffering

        6. Spooling - a buffer to hold output for a device

            1. coordinate concurrent output

                1. if device can serve only one request at a time
        
        7. Device reservation - provides exclusive access to da device

            1. System calls for allocation and de-allocation

            2. Watch out for deadlock

13장

Contiguous logical address space
    • Types:
        Data
            • Numeric, character, binary
        Program
            • Contents defined by file’s creator
        Many types
            • Consider text file, source file, executable file

file attributes

    Information about files are kept in the directory structure, which is maintained on the disk

file operations

    • Write 3 at write pointer location
    • Read 3 at read pointer location
    • Reposition within file - seek

Open files

Several pieces of data are needed to manage open files:
     Open-file table: tracks open files

     File pointer: pointer to last read/write location, per process that has the file open

     File-open count: counter of number of times a file is open to allow removal of data 
     from open-file table when last processes closes it

Open File Locking

Provided by some operating systems and file systems
     Similar to reader-writer locks
     Shared lock similar to reader lock 3 several processes can acquire concurrently
     Exclusive lock similar to writer lock

Mandatory or advisory:
     Mandatory(의무적) 3 access is denied depending on locks held and requested
    (OS ensures locking integrity)
     Advisory(권고적) 3 processes can find status of locks and decide what to do
    (up to software developer)

Access Methods

Sequential Access
    read next (read the next portion & advance a file pointer)
    write next (appends to the end and advance a file pointer)
    reset
• Direct Access 3 file is fixed length logical records
    read n (block number n)
    write n
    position to n
        read next
        write next
    rewrite n
n = relative block number
• Relative block numbers allow OS to decide where file should be placed

Other Access Methods
    Can be built on top of base methods
    • Generally, involve creation of an index for the file
    • Keep index in memory for fast determination of location of data to
    be operated on (consider UPC code plus record of data about that
    item)
    • If too large, index (in memory) of the index (on disk)

Directory Structure

    모든 파일에 대한 정보를 포함하는 노드 모음

Operations Performed on Directory

    • Search for a file
    • Create a file
    • Delete a file
    • List a directory
    • Rename a file
    • Traverse the file system

Directory Organization

    • The directory is organized logically to obtain

    • Efficiency 3 locating a file quickly

    • Naming 3 convenient to users
        두 사용자가 서로 다른 파일에 같은 이름을 사용할 수 있음
        동일한 파일에 여러 개의 다른 이름을 가질 수 있음

Single-Level Directory

    A single directory for all users

    Naming problem

    • Grouping problem

Two-Level Directory

    Separate directory for each user (User File Directory)

    Path name(경로), Can have the same file name for different user, Efficient searching, No grouping capability

Tree-Structured Directories

    Efficient searching

    • Grouping Capability(hierarchical structure)

    • Current directory (working directory)
    3 cd /spell/mail/prog

    Absolute (begins at the root) or relative (from the current directory) path name
        • Creating a new file is done in current directory
        • Delete a file
            rm <file-name>
        • Creating a new subdirectory is done in current directory
            mkdir <dir-name>
        Example: if in current directory /mail
            mkdir count

Acyclic-Graph Directories

    Graph with no cycles
    • Have shared subdirectories and files
        In two or more places

    New directory entry type
        Link - another name (pointer) to an existing file
            기존 파일에 대한 다른 이름 ( 포인터 )
        
        Resolve the link 3 follow pointer to locate the file
            포인터를 따라 파일을 찾음

General Graph Directory

    • How do we guarantee no cycles? 
        Cycles cause problems when traversing file system

     Allow only links to file not subdirectories
     Garbage collection
     Every time a new link is added, use a cycle detection algorithm to determine whether it is OK

Protection

File owner/creator should be able to control:
     what can be done by whom

    • Types of access
         Read: read from the file
         Write: write or rewrite the file
         Execute: Load the file into memory and execute it
         Append: Write new information at the end of the file
         Delete: Delete the file and free its space for possible reuse
         List: List the name and attributes of the file
         Attribute change: Changing the attributes of the file

Access Lists and Groups

    Mode of access: read, write, execute